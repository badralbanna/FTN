{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0afcfdf4cba00ac50e638f57c6797cfbdea9b2bd674f33252d57dc646e66fe742",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.io as sio"
   ]
  },
  {
   "source": [
    "# Sparse coding "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Our model assumes that images, $I$, are encoded linearly by the patterns of neural activation, $\\boldsymbol{a}$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{I}(\\boldsymbol{x}) = \\sum_i a_i \\phi_i (\\boldsymbol{x}) + \\epsilon(\\boldsymbol{x})= \\Phi \\boldsymbol{a} + \\epsilon(\\boldsymbol{x})\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "The _energy_ is given by\n",
    "\n",
    "$$\n",
    "E(\\boldsymbol{a}, \\Phi) = \\underbrace{\\left\\|\\boldsymbol{I}-\\Phi \\boldsymbol{a}\\right\\|^2}_{\\text{preserve information}} + \\lambda \\underbrace{\\sum_i S\\left(\\frac{a_i}{\\sigma}\\right)}_{\\text{sparseness of}\\ \\boldsymbol{a}} \\tag{2}\n",
    "$$\n",
    "\n",
    "Our goal is to find a set of basis functions and activations that minimize $E$ - in other words, that do a good jo constructing the images which keeping activations sparse. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Natural Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the datasets from O&F 1997\n",
    "\n",
    "!wget \"http://www.rctn.org/bruno/sparsenet/IMAGES.mat\"\n",
    "!wget \"http://www.rctn.org/bruno/sparsenet/IMAGES_RAW.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets from http://www.rctn.org/bruno/sparsenet/\n",
    "\n",
    "mat_images = sio.loadmat('IMAGES.mat')\n",
    "natural_imgs = mat_images['IMAGES']\n",
    "mat_images_raw = sio.loadmat('IMAGES_RAW.mat')\n",
    "natural_imgs_raw = mat_images_raw['IMAGESr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot datasets\n",
    "\n",
    "N = 10 # number of images\n",
    "c = 5 # number of columns\n",
    "r = N // c # number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 2*r))\n",
    "for i in range(N):\n",
    "    plt.subplot(r, c, i+1)\n",
    "    plt.imshow(natural_imgs_raw[:,:,i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Natural Images\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 2*r))\n",
    "for i in range(N):\n",
    "    plt.subplot(r, c, i+1)\n",
    "    plt.imshow(natural_imgs[:,:,i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Whitened Natural Images\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a somewhat less natural image\n",
    "\n",
    "!wget \"https://dz2cdn1.dzone.com/storage/temp/3542733-printed-circuit-boards.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading \"natural\" images\n",
    "import imageio\n",
    "circuit_imgs_raw = imageio.imread(\"3542733-printed-circuit-boards.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(circuit_imgs_raw[:,:,i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"\\\"Natural\\\" Images\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_imgs = np.copy(circuit_imgs_raw)\n",
    "w, h, n = circuit_imgs.shape \n",
    "\n",
    "for i in range(n):\n",
    "    current_image = circuit_imgs[:, :, i]\n",
    "    mean = np.mean(current_image)\n",
    "    std = np.std(current_image)\n",
    "    circuit_imgs[:, :, i] = (current_image - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(circuit_imgs[:,:,i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"\\\"Natural\\\" Images\", fontsize=20)\n",
    "plt.subplots_adjust(top=0.9) "
   ]
  },
  {
   "source": [
    "## Sparseness penalty "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-20, 20, 1000)\n",
    "color_map = cm.cool \n",
    "\n",
    "fig, (axS, axP) = plt.subplots(ncols=2, figsize=(8,4))\n",
    "axS.plot(x, np.abs(x), label=r\"$|x|$\", color=color_map(0))\n",
    "axS.plot(x, np.log(1+x**2), label=r\"$\\ln(1+x^2)$\", color=color_map(.3333))\n",
    "axS.plot(x, 1-np.exp(-x**2), label=r\"$1-\\exp(-x^2)$\", color=color_map(.6666))\n",
    "\n",
    "axS.set_xlabel(\"x\")\n",
    "axS.set_ylabel(r\"$S(x)$\")\n",
    "axS.legend()\n",
    "axS.set_xlim(-5, 5)\n",
    "axS.set_ylim(0, 5)\n",
    "\n",
    "f1 = lambda c: np.e**(-np.abs(x))\n",
    "f1_const = np.trapz(f1(x), x)\n",
    "axP.plot(x, f1(x) / f1_const, label=r\"$p \\propto e^{-|x|}$\", color=color_map(0))\n",
    "f2 = lambda c: np.e**(-np.log(1+x**2))\n",
    "f2_const = np.trapz(f2(x), x)\n",
    "axP.plot(x, f2(x) / f2_const, label=r\"$p \\propto e^{-\\ln(1+x^2)}$\", color=color_map(.3333))\n",
    "f3 = lambda c: np.e**(-(1-np.exp(-x**2)))\n",
    "f3_const = np.trapz(f3(x), x)\n",
    "axP.plot(x, f3(x) / f3_const, label=r\"$p \\propto e^{-1+\\exp(-x^2)}$\", color=color_map(.6666))\n",
    "\n",
    "axP.set_xlabel(\"x\")\n",
    "axP.set_ylabel(r\"$p(x)$\")\n",
    "axP.legend()\n",
    "axP.set_xlim(-5, 5)\n",
    "axP.set_ylim(0, 1)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "## Olshausen & Field Model\n",
    "\n",
    "Training the model requires the following steps\n",
    "\n",
    "1. Start with a random set of decoding functions, $\\phi_i$.\n",
    "2. Find the patterns of activity that minimize E given the current $\\phi_i$, $\\min_a E$, for each image $I$. \n",
    "3. Improve the $\\phi_i$ such that they lower the expected value of the energy for all images, $E(\\min_a E)$\n",
    "4. Repeat 2-3 until the $\\phi_i$ and $\\boldsymbol{a}$ converge. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OlshausenField1996Model:\n",
    "    def __init__(self, num_inputs, num_units, batch_size,\n",
    "                    thresh_type=\"soft\",\n",
    "                    nt_max=1000, eps=1e-2,\n",
    "                    lr_r=1e-2, lr_Phi=1e-2, lmda=5e-3):\n",
    "        self.lr_r = lr_r # learning rate of r\n",
    "        self.lr_Phi = lr_Phi # learning rate of Phi\n",
    "        self.lmda = lmda # regularization parameter\n",
    "\n",
    "        self.nt_max = nt_max # Maximum number of simulation time\n",
    "        self.eps = eps  # small value which determines convergence\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_units = num_units\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        assert thresh_type in [\"soft\", \"ln\"]\n",
    "        self.thresh_type = thresh_type\n",
    "        if self.thresh_type == \"soft\":\n",
    "            self._spasity_func = lambda x: np.abs(x)\n",
    "            self._thresh_func = self.soft_thresholding_func\n",
    "        elif self.thesh_type == \"ln\":\n",
    "            self._spasity_func = lambda x: np.ln(1 + x**2)\n",
    "            self._thresh_func = self.ln_thresholding_func\n",
    "        elif self.thesh_type == \"cauchy\":\n",
    "            self._spasity_func = lambda x: np.abs(x)\n",
    "            self._thresh_func = self.cauchy_thresholding_func\n",
    "\n",
    "        # Weights\n",
    "        Phi = np.random.randn(self.num_inputs, self.num_units).astype(np.float32)\n",
    "        self.Phi = Phi * np.sqrt(1/self.num_units)\n",
    "\n",
    "        # activity of neurons\n",
    "        self.r = np.zeros((self.batch_size, self.num_units))\n",
    "    \n",
    "    def initialize_states(self):\n",
    "        self.r = np.zeros((self.batch_size, self.num_units))\n",
    "        \n",
    "    def normalize_rows(self):\n",
    "        self.Phi = self.Phi / np.maximum(np.linalg.norm(self.Phi, ord=2, axis=0, keepdims=True), 1e-8)\n",
    "\n",
    "    # thresholding function of S(x)=|x|\n",
    "    def soft_thresholding_func(self, x, lmda):\n",
    "        return np.maximum(x - lmda, 0) - np.maximum(-x - lmda, 0)\n",
    "\n",
    "    # thresholding function of S(x)=ln(1+x^2)\n",
    "    def ln_thresholding_func(self, x, lmda):\n",
    "        f = 9*lmda*x - 2*np.power(x, 3) - 18*x\n",
    "        g = 3*lmda - np.square(x) + 3\n",
    "        h = np.cbrt(np.sqrt(np.square(f) + 4*np.power(g, 3)) + f)\n",
    "        two_croot = np.cbrt(2) # cubic root of two\n",
    "        return (1/3)*(x - h / two_croot + two_croot*g / (1e-8+h))\n",
    "\n",
    "    # thresholding function https://arxiv.org/abs/2003.12507\n",
    "    def cauchy_thresholding_func(self, x, lmda):\n",
    "        f = 0.5*(x + np.sqrt(np.maximum(x**2 - lmda,0)))\n",
    "        g = 0.5*(x - np.sqrt(np.maximum(x**2 - lmda,0)))\n",
    "        return f*(x>=lmda) + g*(x<=-lmda) \n",
    "\n",
    "    def calculate_error(self, inputs):\n",
    "        error = inputs - self.r @ self.Phi.T\n",
    "        return(error)\n",
    "\n",
    "    def calculate_total_error(self, error):\n",
    "        recon_error = np.mean(error**2)\n",
    "        sparsity_r = self.lmda*np.mean(self._spasity_func(self.r)) \n",
    "        return(recon_error + sparsity_r)\n",
    "\n",
    "    def update_r(self, inputs):\n",
    "        error = self.calculate_error(inputs)\n",
    "        r = self.r + self.lr_r * error @ self.Phi\n",
    "        self.r = self._thresh_func(r, self.lmda)\n",
    "        return(error)\n",
    "\n",
    "    def update_Phi(self, inputs):\n",
    "        error = self.calculate_error(inputs)\n",
    "        dPhi = error.T @ self.r\n",
    "        self.Phi += self.lr_Phi * dPhi\n",
    "        return(error)\n",
    "    \n",
    "    def train(self, inputs):\n",
    "        self.initialize_states() # Reset states\n",
    "        self.normalize_rows() # Normalize weights\n",
    "        \n",
    "        # Input an image patch until latent variables are converged \n",
    "        r_tm1 = self.r # set previous r (t minus 1)\n",
    "        for t in range(self.nt_max):\n",
    "            # Update r without updating weights \n",
    "            error = self.update_r(inputs)\n",
    "            dr = self.r - r_tm1 \n",
    "\n",
    "            # Compute norm of r\n",
    "            dr_norm = np.linalg.norm(dr, ord=2) / (self.eps + np.linalg.norm(r_tm1, ord=2))\n",
    "            r_tm1 = self.r # update r_tm1\n",
    "            \n",
    "            # Check convergence of r, then update weights\n",
    "            if dr_norm < self.eps:\n",
    "                error = self.update_r(inputs)\n",
    "                error = self.update_Phi(inputs)\n",
    "                break\n",
    "            \n",
    "            # If failure to convergence, break and print error\n",
    "            if t >= self.nt_max-2: \n",
    "                print(\"Error at patch:\", iter_)\n",
    "                print(dr_norm)\n",
    "                break\n",
    "        return(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches(input_images, patch_size, batch_size):\n",
    "    H, W, num_images = input_images.shape\n",
    "    \n",
    "    # Set the coordinates of the upper left corner of random image sz X sz image clips\n",
    "    x0 = np.random.randint(0, W-patch_size, batch_size)\n",
    "    y0 = np.random.randint(0, H-patch_size, batch_size)\n",
    "\n",
    "    # Generating inputs\n",
    "    patches_list = []\n",
    "    for i in range(batch_size):        \n",
    "        idx = np.random.randint(0, num_images)\n",
    "        img = input_images[:, :, idx]\n",
    "        clip = img[y0[i]:y0[i]+patch_size, x0[i]:x0[i]+patch_size].flatten()\n",
    "        patches_list.append(clip - np.mean(clip))\n",
    "        \n",
    "    patches = np.array(patches_list) # Input image patches\n",
    "    return(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation constants\n",
    "num_units = 100 # number of neurons (units)\n",
    "patch_size = 16 # image patch size\n",
    "\n",
    "num_iter = 500 # number of iterations\n",
    "batch_size = 250 # Batch size\n",
    "\n",
    "# Image set\n",
    "image_set = natural_imgs\n",
    "\n",
    "# Define model\n",
    "model = OlshausenField1996Model(num_inputs=patch_size**2, \n",
    "                                num_units=num_units,\n",
    "                                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "error_list = [] # List to save errors\n",
    "for iter_ in tqdm(range(num_iter)):\n",
    "    patches = generate_patches(image_set, patch_size, batch_size) # Generating image patches\n",
    "    error = model.train(patches) # train model with patches \n",
    "\n",
    "    error_list.append(model.calculate_total_error(error))\n",
    "    # Print moving average error\n",
    "    if iter_ % 100 == 99:  \n",
    "        print(\"iter: \"+str(iter_+1)+\"/\"+str(num_iter)+\", Moving error:\",\n",
    "              np.mean(error_list[iter_-99:iter_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.plot(np.arange(len(error_list)), np.array(error_list))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_receptive_fields(fields, c=10, title=\"Receptive Fields\"):\n",
    "    num_units, num_inputs = fields.shape\n",
    "    patch_size = int(np.sqrt(num_inputs))\n",
    "    r = num_units // c\n",
    "\n",
    "    fig = plt.figure(figsize=(6, .6*(r+4)))\n",
    "    plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "    for i in tqdm(range(num_units)):\n",
    "        plt.subplot(r, c, i+1)\n",
    "        plt.imshow(np.reshape(fields[i], (patch_size, patch_size)), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_receptive_fields(model.Phi.T)"
   ]
  },
  {
   "source": [
    "## What else could we compare it to?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA, PCA\n",
    "patches = generate_patches(image_set, patch_size, num_iter*batch_size)"
   ]
  },
  {
   "source": [
    "### PCA\n",
    "\n",
    "Principal components analysis (PCA) does not care about sparseness per se. Instead it aims to find receptive fields (basis functions) that captures the most variability in the images. The first basis function captures the most, the second basis function catures the second most, etc..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "pca = PCA(n_components=num_units)\n",
    "pca.fit(patches)\n",
    "pca_filters = pca.components_\n",
    "\n",
    "plot_receptive_fields(pca_filters, title=\"PCA Receptive Fields\")"
   ]
  },
  {
   "source": [
    "### ICA\n",
    "\n",
    "Independant component analysis (ICA) is an approach which attempts to find receptive fields (basis functions) that result in _statistically independant_ activations. In other words \n",
    "\n",
    "$$ p(\\boldsymbol{a}) = \\prod_i p(a_i) $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform ICA\n",
    "ica = FastICA(n_components=num_units)\n",
    "ica.fit(patches)\n",
    "ica_filters = ica.components_\n",
    "\n",
    "plot_receptive_fields(ica_filters, title=\"ICA Receptive Fields\")"
   ]
  }
 ]
}